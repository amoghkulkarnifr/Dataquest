{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "<div><p>So far, we've learned how to select, assign, and analyze data with pandas using pre-cleaned data. In reality, data is rarely in the format needed to perform analysis. Data scientists commonly spend <a href=\"https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/\" target=\"_blank\">over half their time cleaning data</a>, so knowing how to clean \"messy\" data is an extremely important skill.</p>\n",
    "<p>In this mission, we'll learn the basics of data cleaning with pandas as we work with <code>laptops.csv</code>, a CSV file containing information about 1,300 laptop computers. The first five rows of the CSV file are shown below:</p>\n",
    "<table class=\"dataframe\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th>Manufacturer</th>\n",
    "<th>Model Name</th>\n",
    "<th>Category</th>\n",
    "<th>Screen Size</th>\n",
    "<th>Screen</th>\n",
    "<th>CPU</th>\n",
    "<th>RAM</th>\n",
    "<th>Storage</th>\n",
    "<th>GPU</th>\n",
    "<th>Operating System</th>\n",
    "<th>Operating System Version</th>\n",
    "<th>Weight</th>\n",
    "<th>Price (Euros)</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<th>0</th>\n",
    "<td>Apple</td>\n",
    "<td>MacBook Pro</td>\n",
    "<td>Ultrabook</td>\n",
    "<td>13.3\"</td>\n",
    "<td>IPS Panel Retina Display 2560x1600</td>\n",
    "<td>Intel Core i5 2.3GHz</td>\n",
    "<td>8GB</td>\n",
    "<td>128GB SSD</td>\n",
    "<td>Intel Iris Plus Graphics 640</td>\n",
    "<td>macOS</td>\n",
    "<td>NaN</td>\n",
    "<td>1.37kg</td>\n",
    "<td>1339,69</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>1</th>\n",
    "<td>Apple</td>\n",
    "<td>Macbook Air</td>\n",
    "<td>Ultrabook</td>\n",
    "<td>13.3\"</td>\n",
    "<td>1440x900</td>\n",
    "<td>Intel Core i5 1.8GHz</td>\n",
    "<td>8GB</td>\n",
    "<td>128GB Flash Storage</td>\n",
    "<td>Intel HD Graphics 6000</td>\n",
    "<td>macOS</td>\n",
    "<td>NaN</td>\n",
    "<td>1.34kg</td>\n",
    "<td>898,94</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>2</th>\n",
    "<td>HP</td>\n",
    "<td>250 G6</td>\n",
    "<td>Notebook</td>\n",
    "<td>15.6\"</td>\n",
    "<td>Full HD 1920x1080</td>\n",
    "<td>Intel Core i5 7200U 2.5GHz</td>\n",
    "<td>8GB</td>\n",
    "<td>256GB SSD</td>\n",
    "<td>Intel HD Graphics 620</td>\n",
    "<td>No OS</td>\n",
    "<td>NaN</td>\n",
    "<td>1.86kg</td>\n",
    "<td>575,00</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>3</th>\n",
    "<td>Apple</td>\n",
    "<td>MacBook Pro</td>\n",
    "<td>Ultrabook</td>\n",
    "<td>15.4\"</td>\n",
    "<td>IPS Panel Retina Display 2880x1800</td>\n",
    "<td>Intel Core i7 2.7GHz</td>\n",
    "<td>16GB</td>\n",
    "<td>512GB SSD</td>\n",
    "<td>AMD Radeon Pro 455</td>\n",
    "<td>macOS</td>\n",
    "<td>NaN</td>\n",
    "<td>1.83kg</td>\n",
    "<td>2537,45</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>4</th>\n",
    "<td>Apple</td>\n",
    "<td>MacBook Pro</td>\n",
    "<td>Ultrabook</td>\n",
    "<td>13.3\"</td>\n",
    "<td>IPS Panel Retina Display 2560x1600</td>\n",
    "<td>Intel Core i5 3.1GHz</td>\n",
    "<td>8GB</td>\n",
    "<td>256GB SSD</td>\n",
    "<td>Intel Iris Plus Graphics 650</td>\n",
    "<td>macOS</td>\n",
    "<td>NaN</td>\n",
    "<td>1.37kg</td>\n",
    "<td>1803,60</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<p>We can start by reading the data into pandas. Let's look at what happens when we use the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\" target=\"_blank\"><code>pandas.read_csv()</code> function</a> with only the filename argument:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "laptops = pd.read_csv(\"laptops.csv\")\n",
    "```\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "UnicodeDecodeError                        Traceback (most recent call last)\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._convert_tokens()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._convert_with_dtype()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._string_convert()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers._string_box_utf8()\n",
    "\n",
    "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 4: invalid continuation byte\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>We get an error! (The error message has been shortened.) This error references UTF-8, which is a type of <strong>encoding</strong>. Computers, at their lowest levels, can only understand binary - <code>0</code> and <code>1</code>- and encodings are systems for representing characters in binary. </p>\n",
    "<p>Something we can do if our file has an unknown encoding is to try the most common encodings:</p>\n",
    "<ul>\n",
    "<li>UTF-8</li>\n",
    "<li>Latin-1 (also known as ISO-8859-1)</li>\n",
    "<li>Windows-1251</li>\n",
    "</ul>\n",
    "<p>The <code>pandas.read_csv()</code> function has an <code>encoding</code> argument we can use to specify an encoding:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "df = pd.read_csv(\"filename.csv\", encoding=\"some_encoding\")\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Since the <code>pandas.read_csv()</code> function already tried to read in the file with UTF-8 and failed, we know the file's not encoded with that format. Let's try the next most popular encoding in the exercise.</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Import the pandas library</li>\n",
    "<li>Use the <code>pandas.read_csv()</code> function to read the <code>laptops.csv</code> file into a dataframe <code>laptops</code>.<ul>\n",
    "<li>Specify the encoding using the string <code>\"Latin-1\"</code>.</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>Use the <code>DataFrame.info()</code> method to display information about the <code>laptops</code> dataframe.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 4: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 4: invalid continuation byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e5137aefa470>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlaptops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"laptops.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 4: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Error \n",
    "laptops = pd.read_csv(\"laptops.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1303 entries, 0 to 1302\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Manufacturer              1303 non-null   object\n",
      " 1   Model Name                1303 non-null   object\n",
      " 2   Category                  1303 non-null   object\n",
      " 3   Screen Size               1303 non-null   object\n",
      " 4   Screen                    1303 non-null   object\n",
      " 5   CPU                       1303 non-null   object\n",
      " 6   RAM                       1303 non-null   object\n",
      " 7    Storage                  1303 non-null   object\n",
      " 8   GPU                       1303 non-null   object\n",
      " 9   Operating System          1303 non-null   object\n",
      " 10  Operating System Version  1133 non-null   object\n",
      " 11  Weight                    1303 non-null   object\n",
      " 12  Price (Euros)             1303 non-null   object\n",
      "dtypes: object(13)\n",
      "memory usage: 132.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "laptops = pd.read_csv(\"laptops.csv\", encoding=\"Latin-1\")\n",
    "laptops.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning column names \n",
    "\n",
    "<div><p>Below is the output of the <code>DataFrame.info()</code> method from the previous screen:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 1303 entries, 0 to 1302\n",
    "Data columns (total 13 columns):\n",
    " #   Column                    Non-Null Count  Dtype \n",
    "---  ------                    --------------  ----- \n",
    " 0   Manufacturer              1303 non-null   object\n",
    " 1   Model Name                1303 non-null   object\n",
    " 2   Category                  1303 non-null   object\n",
    " 3   Screen Size               1303 non-null   object\n",
    " 4   Screen                    1303 non-null   object\n",
    " 5   CPU                       1303 non-null   object\n",
    " 6   RAM                       1303 non-null   object\n",
    " 7    Storage                  1303 non-null   object\n",
    " 8   GPU                       1303 non-null   object\n",
    " 9   Operating System          1303 non-null   object\n",
    " 10  Operating System Version  1133 non-null   object\n",
    " 11  Weight                    1303 non-null   object\n",
    " 12  Price (Euros)             1303 non-null   object\n",
    "dtypes: object(13)\n",
    "memory usage: 132.5+ KB\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>We can see that every column is represented as the <code>object</code> type, indicating that they are represented by strings, not numbers. Also, one of the columns, <code>Operating System Version</code>, has null values. </p>\n",
    "<p>The column labels have a variety of upper and lowercase letters, as well as spaces and parentheses, which will make them harder to work with and read. One noticeable issue is that the <code>\" Storage\"</code> column name has a space in front of it. These quirks with column labels can sometimes be hard to spot, so removing extra whitespaces from all column names will save us more work in the long run.</p>\n",
    "<p>We can access the column axis of a dataframe using the <a href=\"https://pandas.pydata.org/pandas-docs/stable/basics.html#attributes-and-the-raw-ndarray-s\" target=\"_blank\"><code>DataFrame.columns</code> attribute</a>. This returns an index object — a special type of NumPy ndarray — with the labels of each column:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops.columns)\n",
    "```\n",
    "```\n",
    "Index(['Manufacturer', 'Model Name', 'Category', 'Screen Size', 'Screen',\n",
    "       'CPU', 'RAM', ' Storage', 'GPU', 'Operating System',\n",
    "       'Operating System Version', 'Weight', 'Price (Euros)'],\n",
    "      dtype='object')\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Not only can we use the attribute to view the column labels, we can also assign new labels to the attribute:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "laptops_test = laptops.copy()\n",
    "laptops_test.columns = ['A', 'B', 'C', 'D', 'E',\n",
    "                        'F', 'G', 'H', 'I', 'J',\n",
    "                        'K', 'L', 'M']\n",
    "print(laptops_test.columns)\n",
    "```\n",
    "```\n",
    "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M'], dtype='object')\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Next, let's use the <code>DataFrame.columns</code> attribute to remove whitespaces from the column names.</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Remove any whitespace from the start and end of each column name.<ul>\n",
    "<li>Create an empty list named <code>new_columns</code>.</li>\n",
    "<li>Use a for loop to iterate through each column name using the <code>DataFrame.columns</code> attribute. Inside the body of the for loop:<ul>\n",
    "<li>Use the <a href=\"https://docs.python.org/3.6/library/stdtypes.html#str.strip\" target=\"_blank\"><code>str.strip()</code> method</a> to remove whitespace from the start and end of the string.</li>\n",
    "<li>Append the updated column name to the <code>new_columns</code> list.</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>Assign the updated column names to the <code>DataFrame.columns</code> attribute.</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = []\n",
    "\n",
    "for c in laptops.columns:\n",
    "    new_columns.append(c.strip())\n",
    "\n",
    "laptops.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><p>In the last exercise, we removed whitespaces from the column names. Below is the result:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "Index(['Manufacturer', 'Model Name', 'Category', 'Screen Size', 'Screen',\n",
    "       'CPU', 'RAM', 'Storage', 'GPU', 'Operating System',\n",
    "       'Operating System Version', 'Weight', 'Price (Euros)'],\n",
    "      dtype='object')\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>However, the column labels still have a variety of upper and lowercase letters, as well as parentheses, which will make them harder to work with and read. Let's finish cleaning our column labels by:</p>\n",
    "<ul>\n",
    "<li>Replacing spaces with underscores.</li>\n",
    "<li>Removing special characters.</li>\n",
    "<li>Making all labels lowercase.</li>\n",
    "<li>Shortening any long column names.</li>\n",
    "</ul>\n",
    "<p>We can create a function that uses <a href=\"https://docs.python.org/3/library/stdtypes.html#string-methods\" target=\"_blank\">Python string methods</a> to clean our column labels, and then again use a loop to apply that function to each label. Let's look at an example:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "def clean_col(col):\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"(\",\"\")\n",
    "    col = col.replace(\")\",\"\")\n",
    "    col = col.lower()\n",
    "    return col\n",
    "\n",
    "new_columns = []\n",
    "for c in laptops.columns:\n",
    "    clean_c = clean_col(c)\n",
    "    new_columns.append(clean_c)\n",
    "\n",
    "laptops.columns = new_columns\n",
    "print(laptops.columns)\n",
    "```\n",
    "```\n",
    "Index(['manufacturer', 'model name', 'category', 'screen size', 'screen',\n",
    "       'cpu', 'ram', 'storage', 'gpu', 'operating system',\n",
    "       'operating system version', 'weight', 'price euros'],\n",
    "      dtype='object')\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Our code:</p>\n",
    "<ul>\n",
    "<li>Defined a function, which:<ul>\n",
    "<li>Used the <a href=\"https://docs.python.org/3.6/library/stdtypes.html#str.strip\" target=\"_blank\"><code>str.strip()</code> method</a> to remove whitespace from the start and end of the string.</li>\n",
    "<li>Used the <a href=\"https://docs.python.org/3.6/library/stdtypes.html#str.replace\" target=\"_blank\"><code>str.replace()</code> method</a> to remove parentheses from the string.</li>\n",
    "<li>Used the <a href=\"https://docs.python.org/3.6/library/stdtypes.html#str.lower\" target=\"_blank\"><code>str.lower()</code> method</a> to make the string lowercase.</li>\n",
    "<li>Returns the modified string.</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>Used a loop to apply the function to each item in the index object and assign it back to the <code>DataFrame.columns</code> attribute.</li>\n",
    "<li>Printed the new values for the <code>DataFrame.columns</code> attribute.</li>\n",
    "</ul>\n",
    "<p>Let's use this technique to clean the column labels in our dataframe, adding a few extra cleaning 'chores' along the way.</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Define a function, which accepts a string argument, and:<ul>\n",
    "<li>Removes any whitespace from the start and end of the string.</li>\n",
    "<li>Replaces the substring <code>Operating System</code> with the abbreviation <code>os</code>.</li>\n",
    "<li>Replaces all spaces with underscores.</li>\n",
    "<li>Removes parentheses from the string.</li>\n",
    "<li>Makes the entire string lowercase.</li>\n",
    "<li>Returns the modified string.</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>Use a loop to apply the function to each item in the <code>DataFrame.columns</code> attribute for the <code>laptops</code> dataframe. Assign the result back to the <code>DataFrame.columns</code> attribute.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "laptops = pd.read_csv('laptops.csv', encoding='Latin-1')\n",
    "\n",
    "def clean_col(col_name):\n",
    "    col = col_name.strip()\n",
    "    col = col.replace(\"Operating System\", \"os\")\n",
    "    col = col.replace(\" \", \"_\")\n",
    "    col = col.replace(\"(\", \"\")\n",
    "    col = col.replace(\")\", \"\")\n",
    "    col = col.lower()\n",
    "    \n",
    "    return col \n",
    "\n",
    "new_columns = []\n",
    "for c in laptops.columns:\n",
    "    new_columns.append(clean_col(c))\n",
    "\n",
    "laptops.columns = new_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting string columns to numeric \n",
    "\n",
    "<div><p>We observed earlier that all 13 columns have the <code>object</code> dtype, meaning they're stored as strings.  Let's look at the first few rows of some of our columns:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops.iloc[:5,2:5])\n",
    "```\n",
    "```\n",
    "_   category screen_size                              screen\n",
    "0  Ultrabook       13.3\"  IPS Panel Retina Display 2560x1600\n",
    "1  Ultrabook       13.3\"                            1440x900\n",
    "2   Notebook       15.6\"                   Full HD 1920x1080\n",
    "3  Ultrabook       15.4\"  IPS Panel Retina Display 2880x1800\n",
    "4  Ultrabook       13.3\"  IPS Panel Retina Display 2560x1600\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Of these three columns, we have three different types of text data:</p>\n",
    "<ul>\n",
    "<li><code>category</code>: Purely text data - there are no numeric values.</li>\n",
    "<li><code>screen_size</code>: Numeric data stored as text data because of the <code>\"</code> character.</li>\n",
    "<li><code>screen</code>: A combination of pure text data with numeric data.</li>\n",
    "</ul>\n",
    "<p>Because the values in the <code>screen_size</code> column are stored as text data, we can't sort them numerically. For instance, if we wanted to select laptops with screens 15\" or larger, we'd be unable to do so. </p>\n",
    "<p>Let's convert the <code>screen_size</code> column to numeric next. Whenever we convert text to numeric data, we can follow this data cleaning workflow:</p>\n",
    "<p><img src=\"https://s3.amazonaws.com/dq-content/293/cleaning_workflow.svg\" alt=\"string to numeric cleaning workflow\"></p>\n",
    "<p>The first step is to <strong>explore the data</strong>.  One of the best ways to do this is to use the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html\" target=\"_blank\"><code>Series.unique()</code> method</a> to view all of the unique values in the column:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops[\"screen_size\"].dtype)\n",
    "print(laptops[\"screen_size\"].unique())\n",
    "```\n",
    "```\n",
    "object\n",
    "\n",
    "['13.3\"', '15.6\"', '15.4\"', '14.0\"', '12.0\"', '11.6\"',\n",
    " '17.3\"', '10.1\"', '13.5\"', '12.5\"', '13.0\"', '18.4\"',\n",
    " '13.9\"', '12.3\"', '17.0\"', '15.0\"', '14.1\"',\n",
    " '11.3\"']\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Our next step is to <strong>identify patterns and special cases</strong>. We can observe the following:</p>\n",
    "<ul>\n",
    "<li>All values in this column follow the same pattern - a series of digit and period characters, followed by a quote character (<code>\"</code>). </li>\n",
    "<li>There are no special cases. Every value matches the same pattern.</li>\n",
    "<li>We'll need to convert the column to a <code>float</code> dtype, as the <code>int</code> dtype won't be able to store the decimal values.</li>\n",
    "</ul>\n",
    "<p>Let's identify any patterns and special cases in the <code>ram</code> column next.</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Use the <code>Series.unique()</code> method to identify the unique values in the <code>ram</code> column of the <code>laptops</code> dataframe. Assign the result to <code>unique_ram</code>.</li>\n",
    "<li>After running your code, use the variable inspector to view the unique values in the <code>ram</code> column and identify any patterns.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ram = laptops[\"ram\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing non-digit pattern\n",
    "\n",
    "<div><p>In the last exercise, we identified a clear pattern in the <code>ram</code> column - all values are integers and include the character <code>GB</code> at the end of the string:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "['8GB' '16GB' '4GB' '2GB' '12GB' '6GB' '32GB' '24GB' '64GB']\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>To convert both the <code>ram</code> and <code>screen_size</code> columns to numeric dtypes, we'll have to first <strong>remove the non-digit characters</strong>.</p>\n",
    "<p><img src=\"https://s3.amazonaws.com/dq-content/293/cleaning_workflow.svg\" alt=\"string to numeric cleaning workflow\"></p>\n",
    "<p>The pandas library contains dozens of <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#method-summary\" target=\"_blank\">vectorized string methods</a> we can use to manipulate text data, many of which perform the same operations as Python string methods. Most vectorized string methods are available using the <a href=\"http://pandas.pydata.org/pandas-docs/stable/api.html#string-handling\" target=\"_blank\"><code>Series.str</code> accessor</a>, which means we can access them by adding <code>str</code> between the series name and the method name:</p>\n",
    "<p></p><center><img src=\"https://s3.amazonaws.com/dq-content/346/Syntax.png\" alt=\"vectorized_string_methods\"></center><p></p>\n",
    "<p>In this case, we can use the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.replace.html\" target=\"_blank\"><code>Series.str.replace()</code> method</a>, which is a vectorized version of the Python <code>str.replace()</code> method we used in the previous screen, to remove all the quote characters from every string in the <code>screen_size</code> column:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].str.replace('\"','')\n",
    "print(laptops[\"screen_size\"].unique())\n",
    "```\n",
    "```\n",
    "['13.3', '15.6', '15.4', '14.0', '12.0', '11.6', '17.3',\n",
    " '10.1', '13.5', '12.5', '13.0', '18.4', '13.9', '12.3',\n",
    " '17.0', '15.0', '14.1', '11.3']\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Let's remove the non-digit characters from the <code>ram</code> column next.</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Use the <code>Series.str.replace()</code> method to remove the substring <code>GB</code> from the <code>ram</code> column.</li>\n",
    "<li>Use the <code>Series.unique()</code> method to assign the unique values in the <code>ram</code> column to <code>unique_ram</code>.</li>\n",
    "<li>After running your code, use the variable inspector to verify your changes.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].str.replace('\"','')\n",
    "\n",
    "laptops[\"ram\"] = laptops[\"ram\"].str.replace(\"GB\", \"\")\n",
    "unique_ram = laptops[\"ram\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting columns to numeric Dtypes\n",
    "\n",
    "<div><p>In the last screen, we used the <code>Series.str.replace()</code> method to remove the non-digit characters from the <code>screen_size</code> and <code>ram</code> columns. Now, we can <strong>convert (or cast) the columns to a numeric dtype</strong>. </p>\n",
    "<p><img src=\"https://s3.amazonaws.com/dq-content/293/cleaning_workflow.svg\" alt=\"string to numeric cleaning workflow\"></p>\n",
    "<p>To do this, we use the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.astype.html\" target=\"_blank\"><code>Series.astype()</code> method</a>. To convert the column to a numeric dtype, we can use either <code>int</code> or <code>float</code> as the parameter for the method. Since the <code>int</code> dtype can't store decimal values, we'll convert the <code>screen_size</code> column to the <code>float</code> dtype:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].astype(float)\n",
    "print(laptops[\"screen_size\"].dtype)\n",
    "print(laptops[\"screen_size\"].unique())\n",
    "```\n",
    "```\n",
    "float64\n",
    "\n",
    "[13.3, 15.6, 15.4, 14. , 12. , 11.6, 17.3, 10.1, 13.5, 12.5,\n",
    " 13. , 18.4, 13.9, 12.3, 17. , 15. , 14.1, 11.3]\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Our <code>screen_size</code> column is now the <code>float64</code> dtype. Let's convert the dtype of the <code>ram</code> column to numeric next.</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Use the <code>Series.astype()</code> method to change the <code>ram</code> column to an <code>integer</code> dtype.</li>\n",
    "<li>Use the <code>DataFrame.dtypes</code> attribute to get a list of the column names and types from the <code>laptops</code> dataframe. Assign the result to <code>dtypes</code>.</li>\n",
    "<li>After running your code, use the variable inspector to view the <code>dtypes</code> variable to see the results of your code.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "laptops[\"screen_size\"] = laptops[\"screen_size\"].astype(float)\n",
    "print(laptops[\"screen_size\"].dtype)\n",
    "\n",
    "laptops[\"ram\"] = laptops[\"ram\"].str.replace('GB','')\n",
    "laptops[\"ram\"] = laptops[\"ram\"].astype(int)\n",
    "dtypes = laptops.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming columns \n",
    "\n",
    "<div><p>Now that we've converted our columns to numeric dtypes, the final step is to <strong>rename the column</strong>. This is an optional step, and can be useful if the non-digit values contain information that helps us understand the data. </p>\n",
    "<p><img src=\"https://s3.amazonaws.com/dq-content/293/cleaning_workflow.svg\" alt=\"string to numeric cleaning workflow\"></p>\n",
    "<p>In our case, the quote characters we removed from the <code>screen_size</code> column denoted that the screen size was in inches. As a reminder, here's what the original values looked like:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "['13.3\"', '15.6\"', '15.4\"', '14.0\"', '12.0\"', '11.6\"',\n",
    " '17.3\"', '10.1\"', '13.5\"', '12.5\"', '13.0\"', '18.4\"',\n",
    " '13.9\"', '12.3\"', '17.0\"', '15.0\"', '14.1\"',\n",
    " '11.3\"']\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>To stop us from losing information that helps us understand the data, we can use the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html\" target=\"_blank\"><code>DataFrame.rename()</code> method</a> to rename the column from <code>screen_size</code> to <code>screen_size_inches</code>. </p>\n",
    "<p>Below, we specify the <code>axis=1</code> parameter so pandas knows that we want to rename labels in the column axis:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "laptops.rename({\"screen_size\": \"screen_size_inches\"}, axis=1, inplace=True)\n",
    "print(laptops.dtypes)\n",
    "```\n",
    "```\n",
    "manufacturer           object\n",
    "model_name             object\n",
    "category               object\n",
    "screen_size_inches    float64\n",
    "screen                 object\n",
    "cpu                    object\n",
    "ram                    object\n",
    "storage                object\n",
    "gpu                    object\n",
    "os                     object\n",
    "os_version             object\n",
    "weight                 object\n",
    "price_euros            object\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Note that we can either use <code>inplace=True</code> or assign the result back to the dataframe - both will give us the same results.</p>\n",
    "<p>Let's rename the <code>ram</code> column next and analyze the results.</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Because the <code>GB</code> characters contained useful information about the units (gigabytes) of the laptop's ram, use the <code>DataFrame.rename()</code> method to rename the column from <code>ram</code> to <code>ram_gb</code>.</li>\n",
    "<li>Use the <code>Series.describe()</code> method to return a series of descriptive statistics for the <code>ram_gb</code> column. Assign the result to <code>ram_gb_desc</code>.</li>\n",
    "<li>After you have run your code, use the variable inspector to see the results of your code.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops.rename({\"screen_size\": \"screen_size_inches\"}, axis=1, inplace=True)\n",
    "\n",
    "laptops.rename({\"ram\": \"ram_gb\"}, axis=1, inplace=True)\n",
    "ram_gb_desc = laptops[\"ram_gb\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting values from strings\n",
    "\n",
    "<div><p>Sometimes, it can be useful to extract non-numeric values from within strings. Let's look at the first five values from the <code>gpu</code> (graphics processing unit) column:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops[\"gpu\"].head())\n",
    "```\n",
    "```\n",
    "0    Intel Iris Plus Graphics 640\n",
    "1          Intel HD Graphics 6000\n",
    "2           Intel HD Graphics 620\n",
    "3              AMD Radeon Pro 455\n",
    "4    Intel Iris Plus Graphics 650\n",
    "Name: gpu, dtype: object\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>The information in this column seems to be a manufacturer (Intel, AMD) followed by a model name/number. Let's extract the manufacturer by itself so we can find the most common ones.</p>\n",
    "<p>Because each manufacturer is followed by a whitespace character, we can use the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.split.html\" target=\"_blank\"><code>Series.str.split()</code> method</a> to extract this data:</p>\n",
    "<p><img src=\"https://s3.amazonaws.com/dq-content/293/str_split_2.svg\" alt=\"extracting data from a string, step 2\"></p>\n",
    "<p>This method splits each string on the whitespace; the result is a series containing individual Python lists. Also note that we used parentheses to method chain over multiple lines, which makes our code easier to read.</p>\n",
    "<p>Just like with lists and ndarrays, we can use bracket notation to access the elements in each list in the series. With series, however, we use the <code>str</code> accessor followed by <code>[]</code> (brackets):</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops[\"gpu\"].head().str.split().str[0])\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Above, we used <code>0</code> to select the <em>first</em> element in each list. Below is the result:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "0    Intel\n",
    "1    Intel\n",
    "2    Intel\n",
    "3      AMD\n",
    "4    Intel\n",
    "Name: gpu, dtype: object\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Let's use this technique to extract the manufacturer from the <code>cpu</code> column as well. Here are the first 5 rows of the <code>cpu</code> column:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops[\"cpu\"].head())\n",
    "```\n",
    "```\n",
    "0          Intel Core i5 2.3GHz\n",
    "1          Intel Core i5 1.8GHz\n",
    "2    Intel Core i5 7200U 2.5GHz\n",
    "3          Intel Core i7 2.7GHz\n",
    "4          Intel Core i5 3.1GHz\n",
    "Name: cpu, dtype: object\n",
    "```\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<p>In the example code, we have extracted the manufacturer name from the <code>gpu</code> column, and assigned it to a new column <code>gpu_manufacturer</code>.</p>\n",
    "\n",
    "<ol>\n",
    "<li>Extract the manufacturer name from the <code>cpu</code> column. Assign it to a new column <code>cpu_manufacturer</code>.</li>\n",
    "<li>Use the <code>Series.value_counts()</code> method to find the counts of each manufacturer in <code>cpu_manufacturer</code>. Assign the result to <code>cpu_manufacturer_counts</code>.</li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops[\"gpu_manufacturer\"] = (laptops[\"gpu\"]\n",
    "                                       .str.split()\n",
    "                                       .str[0]\n",
    "                              )\n",
    "laptops[\"cpu_manufacturer\"] = (laptops[\"cpu\"]\n",
    "                                       .str.split()\n",
    "                                       .str[0])\n",
    "cpu_manufacturer_counts = laptops[\"cpu_manufacturer\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correcting bad values \n",
    "\n",
    "<div><p>If your data has been scraped from a webpage or if there was manual data entry involved at some point, you may end up with inconsistent values. Let's look at an example from our <code>os</code> column:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops[\"os\"].value_counts())\n",
    "```\n",
    "```\n",
    "Windows      1125\n",
    "No OS          66\n",
    "Linux          62\n",
    "Chrome OS      27\n",
    "macOS          13\n",
    "Mac OS          8\n",
    "Android         2\n",
    "Name: os, dtype: int64\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>We can see that there are two variations of the Apple operating system — macOS —&nbsp;in our dataset: <code>Mac OS</code> and <code>macOS</code>. One way we can fix this is with the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html\" target=\"_blank\"><code>Series.map()</code> method</a>. The <code>Series.map()</code> method is ideal when we want to change multiple values in a column, but we'll use it now as an opportunity to learn how the method works.</p>\n",
    "<p>The most common way to use <code>Series.map()</code> is with a dictionary. Let's look at an example using a series of misspelled fruit:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(s)\n",
    "```\n",
    "```\n",
    "0       pair\n",
    "1     oranje\n",
    "2    bananna\n",
    "3     oranje\n",
    "4     oranje\n",
    "5     oranje\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>We'll create a dictionary called <code>corrections</code> and pass that dictionary as an argument to <code>Series.map()</code>:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "corrections = {\n",
    "    \"pair\": \"pear\",\n",
    "    \"oranje\": \"orange\",\n",
    "    \"bananna\": \"banana\"\n",
    "}\n",
    "s = s.map(corrections)\n",
    "print(s)\n",
    "```\n",
    "```\n",
    "0       pear\n",
    "1     orange\n",
    "2     banana\n",
    "3     orange\n",
    "4     orange\n",
    "5     orange\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>We can see that each of our corrections were made across our series. One important thing to remember with <code>Series.map()</code> is that if a value from your series doesn't exist as a key in your dictionary, it will convert that value to <code>NaN</code>. Let's see what happens when we run map one more time:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "s = s.map(corrections)\n",
    "print(s)\n",
    "```\n",
    "```\n",
    "0    NaN\n",
    "1    NaN\n",
    "2    NaN\n",
    "3    NaN\n",
    "4    NaN\n",
    "5    NaN\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Because none of the corrected values in our series existed as keys in our dictionary, all values became <code>NaN</code>! It's a very common occurence, especially when working in Jupyter notebook, where you can easily re-run cells.</p>\n",
    "<p>Let's use <code>Series.map()</code> to clean the values in the <code>os</code> column.</p></div>\n",
    "\n",
    "\n",
    "### Instructions \n",
    "\n",
    "\n",
    "<p>We have created a dictionary for you to use with mapping.  Note that we have included both the correct and incorrect spelling of macOS as keys, otherwise we'll end up with null values.</p>\n",
    "\n",
    "<ol>\n",
    "<li>Use the <code>Series.map()</code> method with the <code>mapping_dict</code> dictionary to correct the values in the <code>os</code> column.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    'Android': 'Android',\n",
    "    'Chrome OS': 'Chrome OS',\n",
    "    'Linux': 'Linux',\n",
    "    'Mac OS': 'macOS',\n",
    "    'No OS': 'No OS',\n",
    "    'Windows': 'Windows',\n",
    "    'macOS': 'macOS'\n",
    "}\n",
    "\n",
    "laptops[\"os\"] = laptops[\"os\"].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping missing values \n",
    "\n",
    "<div><p>In previous missions, we've talked briefly about missing values and how both NumPy and pandas represent these as null values. In pandas, null values will be indicated by either <code>NaN</code> or <code>None</code>.</p>\n",
    "<p>Recall that we can use the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isnull.html\" target=\"_blank\"><code>DataFrame.isnull()</code> method</a> to identify  missing values, which returns a boolean dataframe. We can then use the <code>DataFrame.sum()</code> method to give us a count of the <code>True</code> values for each column:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops.isnull().sum())\n",
    "```\n",
    "```\n",
    "manufacturer            0\n",
    "model_name              0\n",
    "category                0\n",
    "screen_size_inches      0\n",
    "screen                  0\n",
    "cpu                     0\n",
    "ram_gb                  0\n",
    "storage                 0\n",
    "gpu                     0\n",
    "os                      0\n",
    "os_version            170\n",
    "weight_kg               0\n",
    "price_euros             0\n",
    "cpu_manufacturer        0\n",
    "screen_resolution       0\n",
    "cpu_speed               0\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>It's now clear that we have only one column with null values, <code>os_version</code>, which has 170 missing values.</p>\n",
    "<p>There are a few options for handling missing values:</p>\n",
    "<ul>\n",
    "<li>Remove any rows that have missing values.</li>\n",
    "<li>Remove any columns that have missing values.</li>\n",
    "<li>Fill the missing values with some other value.</li>\n",
    "<li>Leave the missing values as is.</li>\n",
    "</ul>\n",
    "<p>The first two options are often used to prepare data for machine learning algorithms, which are unable to be used with data that includes null values. We can use the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html\" target=\"_blank\"><code>DataFrame.dropna()</code> method</a> to remove or <strong>drop</strong> rows and columns with null values. </p>\n",
    "<p>The <code>DataFrame.dropna()</code> method accepts an <code>axis</code> parameter, which indicates whether we want to drop along the column or index axis. Let's look at an example:</p>\n",
    "<p><img src=\"https://s3.amazonaws.com/dq-content/293/dropna_1.svg\" alt=\"removing missing values example dataframe\"></p>\n",
    "<p>The default value for the <code>axis</code> parameter is <code>0</code>, so <code>df.dropna()</code> returns an identical result to <code>df.dropna(axis=0</code>):</p>\n",
    "<p><img src=\"https://s3.amazonaws.com/dq-content/293/dropna_2.svg\" alt=\"removing missing values axis=0\"></p>\n",
    "<p>The rows with labels <code>x</code> and <code>z</code> contain null values, so those rows are dropped. Let's look at what happens when we use <code>axis=1</code> to specify the column axis:</p>\n",
    "<p><img src=\"https://s3.amazonaws.com/dq-content/293/dropna_3.svg\" alt=\"removing missing values axis=1\"></p>\n",
    "<p>Only the column with label <code>C</code> contains null values, so, in this case, just one column is removed.</p>\n",
    "<p>Let's practice using <code>DataFrame.dropna()</code> to remove rows and columns:</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Use <code>DataFrame.dropna()</code> to remove any rows from the laptops dataframe that have null values. Assign the result to <code>laptops_no_null_rows</code>.</li>\n",
    "<li>Use <code>DataFrame.dropna()</code> to remove any columns from the laptops dataframe that have null values. Assign the result to <code>laptops_no_null_cols</code>.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops_no_null_rows = laptops.dropna()\n",
    "\n",
    "laptops_no_null_cols = laptops.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing values \n",
    "\n",
    "<div><p>In the previous screen, we learned there are various ways to deal with missing values:</p>\n",
    "<ul>\n",
    "<li>Remove any rows that have missing values.</li>\n",
    "<li>Remove any columns that have missing values.</li>\n",
    "<li>Fill the missing values with some other value.</li>\n",
    "<li>Leave the missing values as is.</li>\n",
    "</ul>\n",
    "<p>While dropping rows or columns is the easiest approach to deal with missing values, it may not always be the <em>best</em> approach. For example, removing a disproportionate amount of one manufacturer's laptops could change our analysis.</p>\n",
    "<p>Because of this, it's a good idea to explore the missing values in the <code>os_version</code> column before making a decision. We can use <code>Series.value_counts()</code> to explore all of the values in the column, but we'll use a parameter we haven't seen before:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops[\"os_version\"].value_counts(dropna=False))\n",
    "```\n",
    "```\n",
    "10      1072\n",
    "NaN      170\n",
    "7         45\n",
    "X          8\n",
    "10 S       8\n",
    "Name: os_version, dtype: int64\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Because we set the <code>dropna</code> parameter to <code>False</code>, the result includes null values. We can see that the majority of values in the column are <code>10</code> and missing values are the next most common.</p>\n",
    "<p>Let's also explore the <code>os</code> column, since it's is closely related to the <code>os_version</code> column. We'll only look at rows in which the <code>os_version</code> is missing:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "os_with_null_v = laptops.loc[laptops[\"os_version\"].isnull(),\"os\"]\n",
    "print(os_with_null_v.value_counts())\n",
    "```\n",
    "```\n",
    "No OS        66\n",
    "Linux        62\n",
    "Chrome OS    27\n",
    "macOS        13\n",
    "Android       2\n",
    "Name: os, dtype: int64\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Immediately, we can observe a few things:</p>\n",
    "<ul>\n",
    "<li>The most frequent value is \"No OS\". This is important to note because if there is no os, there <em>shouldn't</em> be a version defined in the <code>os_version</code> column.</li>\n",
    "<li>Thirteen of the laptops that come with macOS do not specify the version. We can use our knowledge of <a href=\"https://en.wikipedia.org/wiki/MacOS\" target=\"_blank\">MacOS</a> to confirm that <code>os_version</code> should be equal to <code>X</code>.</li>\n",
    "</ul>\n",
    "<p>In both of these cases, we can fill the missing values to make our data more correct. For the rest of the values, it's probably best to leave them as missing so we don't remove important values.</p>\n",
    "<p>We can use assignment with a boolean comparison to perform this replacement, like below:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "laptops.loc[laptops[\"os\"] == \"macOS\", \"os_version\"] = \"X\"\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>For rows with <code>No OS</code> values, let's replace the missing value in the <code>os_version</code> column with the value <code>Version Unknown</code>.</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Use a boolean array to identify rows that have the value <code>No OS</code> for the <code>os</code> column. Then, use assignment to assign the value <code>Version Unknown</code> to the <code>os_version</code> column for those rows.</li>\n",
    "<li>\n",
    "<p>Use the syntax below to create <code>value_counts_after</code> variable:</p>\n",
    "<p><code>value_counts_after = laptops.loc[laptops[\"os_version\"].isnull(), \"os\"].value_counts()</code></p>\n",
    "</li>\n",
    "<li>\n",
    "<p>After running your code, use the variable inspector to look at the difference between <code>value_counts_before</code> and <code>value_counts_after</code>.</p>\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_before = laptops.loc[laptops[\"os_version\"].isnull(), \"os\"].value_counts()\n",
    "laptops.loc[laptops[\"os\"] == \"macOS\", \"os_version\"] = \"X\"\n",
    "\n",
    "laptops.loc[laptops[\"os\"] == \"No OS\", \"os_version\"] = \"Version Unknown\"\n",
    "value_counts_after = laptops.loc[laptops[\"os_version\"].isnull(), \"os\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Clean a string column \n",
    "\n",
    "<div><p>Now it's time to practice what we've learned so far! In this challenge, we'll clean the <code>weight</code> column. Let's look at a sample of the data in that column:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "print(laptops[\"weight\"].head())\n",
    "```\n",
    "```\n",
    "0    1.37kg\n",
    "1    1.34kg\n",
    "2    1.86kg\n",
    "3    1.83kg\n",
    "4    1.37kg\n",
    "Name: Weight, dtype: object\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>Your challenge is to convert the values in this column to numeric values. As a reminder, here's the data cleaning workflow you can use:</p>\n",
    "<p><img src=\"https://s3.amazonaws.com/dq-content/293/cleaning_workflow.svg\" alt=\"string to numeric cleaning workflow\"></p>\n",
    "<p>While it appears that the <code>weight</code> column may just need the <code>kg</code> characters removed from the end of each string, there is one special case - one of the values ends with <code>kgs</code>, so you'll have to remove both <code>kg</code> and <code>kgs</code> characters.</p>\n",
    "<p>In the last step of this challenge, we'll also ask you to use the <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\" target=\"_blank\"><code>DataFrame.to_csv()</code> method</a> to save the cleaned data to a CSV file. It's a good idea to save a CSV when you finish cleaning in case you wish to do analysis later.</p>\n",
    "<p>We can use the following syntax to save a CSV:</p>\n",
    "</div>\n",
    "\n",
    "```\n",
    "df.to_csv('filename.csv', index=False)\n",
    "```\n",
    "\n",
    "<div>\n",
    "<p>By default, pandas will save the index labels as a column in the CSV file. Our dataset has integer labels that don't contain any data, so we don't need to save the index.</p>\n",
    "<p>Don't be discouraged if this challenge takes a few attempts to get correct. Working iteratively is a great way to work, and this challenge is more difficult than exercises you have previously completed. We have included some extra hints, but we encourage you to try without the hints first; only use them if you need them!</p></div>\n",
    "\n",
    "### Instructions \n",
    "\n",
    "<ol>\n",
    "<li>Convert the values in the <code>weight</code> column to numeric values.</li>\n",
    "<li>Rename the <code>weight</code> column to <code>weight_kg</code>.</li>\n",
    "<li>Use the <code>DataFrame.to_csv()</code> method to save the laptops dataframe to a CSV file <code>laptops_cleaned.csv</code> <em>without</em> index labels.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2kg     121\n",
      "2.1kg      58\n",
      "2.4kg      44\n",
      "2.3kg      41\n",
      "2.5kg      38\n",
      "         ... \n",
      "0.99kg      1\n",
      "2.21kg      1\n",
      "1.55kg      1\n",
      "1.79kg      1\n",
      "4.4kg       1\n",
      "Name: weight, Length: 179, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(laptops[\"weight\"].value_counts(dropna=False))\n",
    "\n",
    "laptops[\"weight\"] = laptops[\"weight\"].str.replace(\"kgs\", \"\")\n",
    "laptops[\"weight\"] = laptops[\"weight\"].str.replace(\"kg\", \"\")\n",
    "\n",
    "laptops[\"weight\"] = laptops[\"weight\"].astype(float)\n",
    "\n",
    "laptops.rename({\"weight\" : \"weight_kg\"}, axis=1, inplace=True)\n",
    "\n",
    "laptops.to_csv(\"laptops_cleaned.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
